{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load your Excel file into a DataFrame\n",
    "df = pd.read_csv('./original dataset.csv')\n",
    "\n",
    "# Step 2: Create a list of new row names (index names)\n",
    "\n",
    "new_row_names = [\n",
    "    'frame.interface_id',\n",
    "    'frame.dlt',\n",
    "    'frame.offset_shift',\n",
    "    'frame.time_epoch',\n",
    "    'frame.time_delta',\n",
    "    'frame.time_delta_displayed',\n",
    "    'frame.time_relative',\n",
    "    'frame.len',\n",
    "    'frame.cap_len',\n",
    "    'frame.marked',\n",
    "    'frame.ignored',\n",
    "    'radiotap.version',\n",
    "    'radiotap.pad',\n",
    "    'radiotap.length',\n",
    "    'radiotap.present.tsft',\n",
    "    'radiotap.present.flags',\n",
    "    'radiotap.present.rate',\n",
    "    'radiotap.present.channel',\n",
    "    'radiotap.present.fhss',\n",
    "    'radiotap.present.dbm_antsignal',\n",
    "    'radiotap.present.dbm_antnoise',\n",
    "    'radiotap.present.lock_quality',\n",
    "    'radiotap.present.tx_attenuation',\n",
    "    'radiotap.present.db_tx_attenuation',\n",
    "    'radiotap.present.dbm_tx_power',\n",
    "    'radiotap.present.antenna',\n",
    "    'radiotap.present.db_antsignal',\n",
    "    'radiotap.present.db_antnoise',\n",
    "    'radiotap.present.rxflags',\n",
    "    'radiotap.present.xchannel',\n",
    "    'radiotap.present.mcs',\n",
    "    'radiotap.present.ampdu',\n",
    "    'radiotap.present.vht',\n",
    "    'radiotap.present.reserved',\n",
    "    'radiotap.present.rtap_ns',\n",
    "    'radiotap.present.vendor_ns',\n",
    "    'radiotap.present.ext',\n",
    "    'radiotap.mactime',\n",
    "    'radiotap.flags.cfp',\n",
    "    'radiotap.flags.preamble',\n",
    "    'radiotap.flags.wep',\n",
    "    'radiotap.flags.frag',\n",
    "    'radiotap.flags.fcs',\n",
    "    'radiotap.flags.datapad',\n",
    "    'radiotap.flags.badfcs',\n",
    "    'radiotap.flags.shortgi',\n",
    "    'radiotap.datarate',\n",
    "    'radiotap.channel.freq',\n",
    "    'radiotap.channel.type.turbo',\n",
    "    'radiotap.channel.type.cck',\n",
    "    'radiotap.channel.type.ofdm',\n",
    "    'radiotap.channel.type.2ghz',\n",
    "    'radiotap.channel.type.5ghz',\n",
    "    'radiotap.channel.type.passive',\n",
    "    'radiotap.channel.type.dynamic',\n",
    "    'radiotap.channel.type.gfsk',\n",
    "    'radiotap.channel.type.gsm',\n",
    "    'radiotap.channel.type.sturbo',\n",
    "    'radiotap.channel.type.half',\n",
    "    'radiotap.channel.type.quarter',\n",
    "    'radiotap.dbm_antsignal',\n",
    "    'radiotap.antenna',\n",
    "    'radiotap.rxflags.badplcp',\n",
    "    'wlan.fc.type_subtype',\n",
    "    'wlan.fc.version',\n",
    "    'wlan.fc.type',\n",
    "    'wlan.fc.subtype',\n",
    "    'wlan.fc.ds',\n",
    "    'wlan.fc.frag',\n",
    "    'wlan.fc.retry',\n",
    "    'wlan.fc.pwrmgt',\n",
    "    'wlan.fc.moredata',\n",
    "    'wlan.fc.protected',\n",
    "    'wlan.fc.order',\n",
    "    'wlan.duration',\n",
    "    'wlan.ra',\n",
    "    'wlan.da',\n",
    "    'wlan.ta',\n",
    "    'wlan.sa',\n",
    "    'wlan.bssid',\n",
    "    'wlan.frag',\n",
    "    'wlan.seq',\n",
    "    'wlan.bar.type',\n",
    "    'wlan.ba.control.ackpolicy',\n",
    "    'wlan.ba.control.multitid',\n",
    "    'wlan.ba.control.cbitmap',\n",
    "    'wlan.bar.compressed.tidinfo',\n",
    "    'wlan.ba.bm',\n",
    "    'wlan.fcs_good',\n",
    "    'wlan_mgt.fixed.capabilities.ess',\n",
    "    'wlan_mgt.fixed.capabilities.ibss',\n",
    "    'wlan_mgt.fixed.capabilities.cfpoll.ap',\n",
    "    'wlan_mgt.fixed.capabilities.privacy',\n",
    "    'wlan_mgt.fixed.capabilities.preamble',\n",
    "    'wlan_mgt.fixed.capabilities.pbcc',\n",
    "    'wlan_mgt.fixed.capabilities.agility',\n",
    "    'wlan_mgt.fixed.capabilities.spec_man',\n",
    "    'wlan_mgt.fixed.capabilities.short_slot_time',\n",
    "    'wlan_mgt.fixed.capabilities.apsd',\n",
    "    'wlan_mgt.fixed.capabilities.radio_measurement',\n",
    "    'wlan_mgt.fixed.capabilities.dsss_ofdm',\n",
    "    'wlan_mgt.fixed.capabilities.del_blk_ack',\n",
    "    'wlan_mgt.fixed.capabilities.imm_blk_ack',\n",
    "    'wlan_mgt.fixed.listen_ival',\n",
    "    'wlan_mgt.fixed.current_ap',\n",
    "    'wlan_mgt.fixed.status_code',\n",
    "    'wlan_mgt.fixed.timestamp',\n",
    "    'wlan_mgt.fixed.beacon',\n",
    "    'wlan_mgt.fixed.aid',\n",
    "    'wlan_mgt.fixed.reason_code',\n",
    "    'wlan_mgt.fixed.auth.alg',\n",
    "    'wlan_mgt.fixed.auth_seq',\n",
    "    'wlan_mgt.fixed.category_code',\n",
    "    'wlan_mgt.fixed.htact',\n",
    "    'wlan_mgt.fixed.chanwidth',\n",
    "    'wlan_mgt.fixed.fragment',\n",
    "    'wlan_mgt.fixed.sequence',\n",
    "    'wlan_mgt.tagged.all',\n",
    "    'wlan_mgt.ssid',\n",
    "    'wlan_mgt.ds.current_channel',\n",
    "    'wlan_mgt.tim.dtim_count',\n",
    "    'wlan_mgt.tim.dtim_period',\n",
    "    'wlan_mgt.tim.bmapctl.multicast',\n",
    "    'wlan_mgt.tim.bmapctl.offset',\n",
    "    'wlan_mgt.country_info.environment',\n",
    "    'wlan_mgt.rsn.version',\n",
    "    'wlan_mgt.rsn.gcs.type',\n",
    "    'wlan_mgt.rsn.pcs.count',\n",
    "    'wlan_mgt.rsn.akms.count',\n",
    "    'wlan_mgt.rsn.akms.type',\n",
    "    'wlan_mgt.rsn.capabilities.preauth',\n",
    "    'wlan_mgt.rsn.capabilities.no_pairwise',\n",
    "    'wlan_mgt.rsn.capabilities.ptksa_replay_counter',\n",
    "    'wlan_mgt.rsn.capabilities.gtksa_replay_counter',\n",
    "    'wlan_mgt.rsn.capabilities.mfpr',\n",
    "    'wlan_mgt.rsn.capabilities.mfpc',\n",
    "    'wlan_mgt.rsn.capabilities.peerkey',\n",
    "    'wlan_mgt.tcprep.trsmt_pow',\n",
    "    'wlan_mgt.tcprep.link_mrg',\n",
    "    'wlan.wep.iv',\n",
    "    'wlan.wep.key',\n",
    "    'wlan.wep.icv',\n",
    "    'wlan.tkip.extiv',\n",
    "    'wlan.ccmp.extiv',\n",
    "    'wlan.qos.tid',\n",
    "    'wlan.qos.priority',\n",
    "    'wlan.qos.eosp',\n",
    "    'wlan.qos.ack',\n",
    "    'wlan.qos.amsdupresent',\n",
    "    'wlan.qos.buf_state_indicated',\n",
    "    'wlan.qos.bit4',\n",
    "    'wlan.qos.txop_dur_req',\n",
    "    'wlan.qos.buf_state_indicated',\n",
    "    'data.len',\n",
    "    'class'\n",
    "     # Ensure 'class' is included\n",
    "]\n",
    "\n",
    "\n",
    "  # Replace with your actual list of names\n",
    "\n",
    "# Step 3: Replace the row names (index) with the new names\n",
    "df.columns = new_row_names\n",
    "\n",
    "# Step 4: Save the updated DataFrame back to an Excel file\n",
    "df.to_csv('updated_excel_file.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['frame.interface_id', 'frame.dlt', 'frame.offset_shift',\n",
       "       'frame.time_epoch', 'frame.time_delta', 'frame.time_delta_displayed',\n",
       "       'frame.time_relative', 'frame.len', 'frame.cap_len', 'frame.marked',\n",
       "       ...\n",
       "       'wlan.qos.priority', 'wlan.qos.eosp', 'wlan.qos.ack',\n",
       "       'wlan.qos.amsdupresent', 'wlan.qos.buf_state_indicated',\n",
       "       'wlan.qos.bit4', 'wlan.qos.txop_dur_req',\n",
       "       'wlan.qos.buf_state_indicated', 'data.len', 'class'],\n",
       "      dtype='object', length=155)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Convert all columns to numeric values, coercing when necessary\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill NaN values with the median of each column\n",
    "df.fillna(df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any NaN values left? 23025720\n"
     ]
    }
   ],
   "source": [
    "print(\"Are there any NaN values left?\", df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'class' in df.columns:\n",
    "    df['class'] = df['class'].astype(str)\n",
    "    df['label'] = df['class'].apply(lambda x: 0 if x.strip().lower() == 'normal' else 1)\n",
    "    df = df.drop(columns=['class'])\n",
    "else:\n",
    "    raise ValueError(\"The 'class' column is missing from the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling completed and saved to ./updated_excel_file.csv.csv.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = './updated_excel_file.csv.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"Labeling completed and saved to {output_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarve\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:1051: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\sarve\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:1056: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\sarve\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:1076: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any NaN values left after scaling? 22450077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "df = pd.read_csv(output_file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Are there any NaN values left after scaling?\", np.isnan(X_scaled).sum())\n",
    "\n",
    "if np.isnan(X_scaled).sum() > 0:\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=np.nanmean(X_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarve\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:108: RuntimeWarning: divide by zero encountered in divide\n",
      "  msb = ssbn / float(dfbn)\n",
      "c:\\Users\\sarve\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:108: RuntimeWarning: invalid value encountered in divide\n",
      "  msb = ssbn / float(dfbn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['wlan_mgt.rsn.capabilities.mfpr', 'wlan_mgt.rsn.capabilities.mfpc',\n",
      "       'wlan_mgt.rsn.capabilities.peerkey', 'wlan_mgt.tcprep.trsmt_pow',\n",
      "       'wlan_mgt.tcprep.link_mrg', 'wlan.wep.iv', 'wlan.wep.key',\n",
      "       'wlan.wep.icv', 'wlan.tkip.extiv', 'wlan.ccmp.extiv', 'wlan.qos.tid',\n",
      "       'wlan.qos.priority', 'wlan.qos.eosp', 'wlan.qos.ack',\n",
      "       'wlan.qos.amsdupresent', 'wlan.qos.buf_state_indicated',\n",
      "       'wlan.qos.bit4', 'wlan.qos.txop_dur_req',\n",
      "       'wlan.qos.buf_state_indicated.1', 'data.len'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=20)  # Adjust k based on your needs\n",
    "X_new = selector.fit_transform(X_scaled, y)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any NaN values left after scaling? 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Are there any NaN values left after scaling?\", np.isnan(X_scaled).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575643, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class IDS_Environment:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_actions = 2  # Normal or Intrusion (0 or 1)\n",
    "        self.current_index = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.current_index = 0\n",
    "        return self.X[self.current_index]\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 1 if action == self.y[self.current_index] else -1\n",
    "        self.current_index += 1\n",
    "        \n",
    "        done = self.current_index >= len(self.y)\n",
    "        next_state = self.X[self.current_index] if not done else None\n",
    "        \n",
    "        return next_state, reward, done\n",
    "\n",
    "# Initialize the environment\n",
    "env = IDS_Environment(X_new, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize DQN\n",
    "input_dim = X_new.shape[1]\n",
    "output_dim = env.n_actions\n",
    "dqn = DQN(input_dim, output_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(dqn.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Environment step method returned None for next_state. Resetting environment.\n",
      "Episode 1/5, Loss: 38849124.49477647\n",
      "Warning: Environment step method returned None for next_state. Resetting environment.\n",
      "Episode 2/5, Loss: 303683.8642030822\n",
      "Warning: Environment step method returned None for next_state. Resetting environment.\n",
      "Episode 3/5, Loss: 298700.23904386855\n",
      "Warning: Environment step method returned None for next_state. Resetting environment.\n",
      "Episode 4/5, Loss: 257170.3074230735\n",
      "Warning: Environment step method returned None for next_state. Resetting environment.\n",
      "Episode 5/5, Loss: 186245.55755914655\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize DQN\n",
    "input_dim = X_new.shape[1]  # Assuming X_new is defined\n",
    "output_dim = env.n_actions  # Assuming env is defined\n",
    "dqn = DQN(input_dim, output_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(dqn.parameters(), lr=0.001)  # Reduced learning rate\n",
    "\n",
    "def train_dqn(env, dqn, optimizer, criterion, n_episodes=5, gamma=0.99, epsilon=0.1):\n",
    "    dqn.train()\n",
    "    for episode in range(n_episodes):\n",
    "        state = env.reset()\n",
    "        if state is None:\n",
    "            raise ValueError(\"The environment reset method returned None.\")\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)  # Shape [1, num_features]\n",
    "\n",
    "        done = False\n",
    "        total_loss = 0\n",
    "\n",
    "        while not done:\n",
    "            if random.random() < epsilon:\n",
    "                action = random.choice(range(env.n_actions))  # Ensure action is within valid range\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    q_values = dqn(state)\n",
    "                    action = q_values.argmax().item()\n",
    "\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if next_state is None:\n",
    "                print(f\"Warning: Environment step method returned None for next_state. Resetting environment.\")\n",
    "                next_state = env.reset()  # Reset environment if needed\n",
    "            next_state = torch.FloatTensor(next_state).unsqueeze(0) if next_state is not None else None\n",
    "            \n",
    "            reward = torch.tensor([reward], dtype=torch.float32)\n",
    "            if next_state is not None:\n",
    "                with torch.no_grad():\n",
    "                    max_next_q_value = dqn(next_state).max()\n",
    "                target = reward + gamma * max_next_q_value\n",
    "            else:\n",
    "                target = reward\n",
    "\n",
    "            # Ensure target and output have consistent shapes\n",
    "            target = target.unsqueeze(0)  # Shape [1]\n",
    "            output = dqn(state)[0, action]  # Shape [1]\n",
    "\n",
    "            # Check for NaN values in target and output\n",
    "            if torch.isnan(target).any() or torch.isinf(target).any():\n",
    "                print(f\"NaN detected in target\")\n",
    "                continue\n",
    "            if torch.isnan(output).any() or torch.isinf(output).any():\n",
    "                print(f\"NaN detected in output\")\n",
    "                continue\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # Check for NaN values in loss\n",
    "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "                print(f\"NaN detected in loss\")\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(dqn.parameters(), 1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            state = next_state\n",
    "\n",
    "        print(f\"Episode {episode + 1}/{n_episodes}, Loss: {total_loss}\")\n",
    "\n",
    "# Ensure the env's state and action space sizes are consistent with your DQN model.\n",
    "# Then train the DQN using the function:\n",
    "train_dqn(env, dqn, optimizer, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/10, Total Reward: 575643\n",
      "Episode 2/10, Total Reward: 575643\n",
      "Episode 3/10, Total Reward: 575643\n",
      "Episode 4/10, Total Reward: 575643\n",
      "Episode 5/10, Total Reward: 575643\n",
      "Episode 6/10, Total Reward: 575643\n",
      "Episode 7/10, Total Reward: 575643\n",
      "Episode 8/10, Total Reward: 575643\n",
      "Episode 9/10, Total Reward: 575643\n",
      "Episode 10/10, Total Reward: 575643\n",
      "Average Reward over 10 episodes: 575643.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_dqn(env, dqn, n_episodes=10, epsilon=0.0):\n",
    "    dqn.eval()  # Set the model to evaluation mode\n",
    "    total_rewards = []\n",
    "    for episode in range(n_episodes):\n",
    "        state = env.reset()\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)  # Shape [1, num_features]\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            with torch.no_grad():\n",
    "                q_values = dqn(state)\n",
    "                action = q_values.argmax().item()  # Select the action with the highest Q-value\n",
    "\n",
    "            next_state, reward, done = env.step(action)\n",
    "            next_state = torch.FloatTensor(next_state).unsqueeze(0) if next_state is not None else None\n",
    "\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "        print(f\"Episode {episode + 1}/{n_episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "    average_reward = np.mean(total_rewards)\n",
    "    print(f\"Average Reward over {n_episodes} episodes: {average_reward}\")\n",
    "\n",
    "# Example usage\n",
    "evaluate_dqn(env, dqn, n_episodes=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
